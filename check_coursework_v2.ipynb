{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIaqPNWwYn-c"
      },
      "source": [
        "#Neural network coursework checker\n",
        "This notebook is for checking ME4/MSc Machine Learning neural network coursework submission. You should run your model through this to check that you are getting the right answer prior to submission. \n",
        "**If you get the wrong answers out, this is an indication that you need to change your model, not an indication that this script is incorrect.**\n",
        "\n",
        "Also note that while this script may find many errors, it will not find all and that you are ultimately responsible for double-checking that what you submit is correct.\n",
        "\n",
        "This script is not used for assessment (but note that similar routines are used to load the model etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBmTOrSGY6UL"
      },
      "source": [
        "---\n",
        "###Tidy up space (not normally needed)\n",
        "The section below is just used for clearing any previously uploaded files. You should not normally need to run it, unless you have had crashes. If you run it you will need to re-upload the datasets. You can always open the file manager on the left hand side to look at the files too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "73fIVRGcU490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
            "'rm' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
            "'rm' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
            "'rm' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "#clear all files from the work area - only really need to do this if uploading\n",
        "#files multiple times\n",
        "!ls -lh\n",
        "!rm *.csv\n",
        "!rm *.h5\n",
        "!rm *.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR1sP882ZYZf"
      },
      "source": [
        "---\n",
        "##Upload model and test with data\n",
        "This section loads the files selected (note -- select both .h5 and .txt for scaling parameters if you have them, otherwise it will not do any scaling), and runs the training data you have uploaded through the model. You should check that this all works OK -- you don't get any errors -- and that the fraction correct matches what you saw when you trained it. Note that this only works with one model at a time so you will need to run it twice -- once each for dataset 1 and 2. \n",
        "\n",
        "Also note that if you upload files with the same name multiple times then they will be renamed to e.g. xyz123-2 (1).h5 which will cause issues - the script tries to catch this by deleting any uploaded files at the end, but if it crashes you may need to delete all uploaded files using the section at the top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AK8IyjA0PsgJ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8216/4119057372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "#upload model files\n",
        "import numpy as np\n",
        "import os.path\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#import for bold font\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "from google.colab import files\n",
        "print('Note: please process one model at a time - this tool is not designed to do both')\n",
        "print('Upload one .h5 file and corresponding scaling file (if using one) here')\n",
        "uploaded = files.upload()\n",
        "h5file = 'lb1922-1.h5'\n",
        "scalefile = 'lb1922-1.txt'\n",
        "scale_exists = True\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  filename, file_extension = os.path.splitext(fn)\n",
        "  if file_extension == '.h5':\n",
        "    h5file = fn\n",
        "    h5filejustname = filename\n",
        "  if file_extension == '.txt':\n",
        "    scalefile = fn\n",
        "    scalefilejustname = filename\n",
        "    scale_exists = True\n",
        "  #print(\"Ext: \", file_extension)\n",
        "  \n",
        "  filebase = filename\n",
        "  \n",
        "#print('File base is: ', filebase)\n",
        "print('H5 file is: ', h5file)\n",
        "print('Scale file is: ', scalefile)\n",
        "\n",
        "#check files match\n",
        "if h5filejustname != scalefilejustname:\n",
        "  print(\"**Error: Mismatch in filenames. The h5 and txt files should have the same name (apart from the extension).**\")\n",
        "  os.remove(h5file)\n",
        "  if scale_exists:\n",
        "    os.remove(scalefile)\n",
        "  from sys import exit\n",
        "  exit()\n",
        "\n",
        "#check names are lowercase\n",
        "if h5filejustname.lower() != h5filejustname:\n",
        "  print(\"**Error: filenames should all be lowercase**\")\n",
        "  os.remove(h5file)\n",
        "  if scale_exists:\n",
        "    os.remove(scalefile)\n",
        "\n",
        "  from sys import exit\n",
        "  exit()\n",
        "\n",
        "if h5file.count(\"-\") != 1:\n",
        "  print(\"**Error: file should have form \\\"xyz123-1.h5\\\". Make sure you have used the \\ncorrect name delimiters; these should be hyphens (-).**\")\n",
        "  os.remove(h5file)\n",
        "  if scale_exists:\n",
        "    os.remove(scalefile)\n",
        "  from sys import exit\n",
        "  exit()\n",
        "\n",
        "#extract names\n",
        "username,dataset = h5filejustname.split(\"-\")\n",
        "\n",
        "if len(dataset) != 1:\n",
        "  print(\"**Error: file should have form \\\"xyz123-1.h5\\\". Make sure your dataset value is correct.**\")\n",
        "  os.remove(h5file)\n",
        "  if scale_exists:\n",
        "    os.remove(scalefile)\n",
        "  from sys import exit\n",
        "  exit()\n",
        "\n",
        "\n",
        "#don't do this on Colab\n",
        "# #user defined parameters (change these as necessary):\n",
        "# #put your name here:\n",
        "# username = 'xyz123'\n",
        "# #set which dataset to use:\n",
        "# dataset = 1\n",
        "\n",
        "#filebase = username.lower()+'-'+np.str(dataset)\n",
        "\n",
        "#dataset = filebase[-1]\n",
        "#print('Dataset considered is: ',dataset)\n",
        "\n",
        "#load in student model\n",
        "model = load_model(h5file,compile=False)\n",
        "\n",
        "if scale_exists:\n",
        "  if os.path.exists(scalefile):\n",
        "      print(scalefile+' exists - loading in scaling parameters')\n",
        "      scaleArray = np.loadtxt(scalefile)\n",
        "  else:\n",
        "      print(scalefile+' not found - assuming no scaling')\n",
        "      scaleArray = np.array([np.zeros([6,]), np.ones([6,])])\n",
        "else:\n",
        "    print('No scale file provided - assuming no scaling')\n",
        "    scaleArray = np.array([np.zeros([6,]), np.ones([6,])])\n",
        "\n",
        "#load in the data provided to the students\n",
        "df = pd.read_csv('http://pogo.software/me4ml/dataset' + np.str(dataset) + '.csv')\n",
        "\n",
        "Lt = np.array(df['Arm length (m)'][:])\n",
        "Wt = np.array(df['Ball weight (kg)'][:])\n",
        "Rt = np.array(df['Ball radius (mm)'][:])\n",
        "Tt = np.array(df['Air temperature (deg C)'][:])\n",
        "Et = np.array(df['Spring constant (N per m)'][:])\n",
        "Dt = np.array(df['Device weight (kg)'][:])\n",
        "Ot = np.array(df['Target hit'][:])\n",
        "XtUnscaled = np.column_stack([Lt, Wt, Rt, Tt, Et, Dt])\n",
        "\n",
        "# use values to scale validation data in XvUnscaled (whose shape is [number_of_validations,6])\n",
        "Xt = (XtUnscaled-scaleArray[0,:])/scaleArray[1,:]\n",
        "\n",
        "Yt = to_categorical(Ot)\n",
        "#run the data through the model\n",
        "Yt_predict = model.predict(Xt)\n",
        "\n",
        "#output a summary of the model if you wish\n",
        "#model.summary()\n",
        "\n",
        "\n",
        "number_correct = 0\n",
        "for i in range(len(Yt)):\n",
        "    if np.round(Yt[i, 0]) == np.round(Yt_predict[i, 0]):\n",
        "        number_correct += 1\n",
        "\n",
        "fraction_correct = 1.0 * number_correct / len(Yt_predict)\n",
        "\n",
        "\n",
        "\n",
        "printmd(\"**Fraction correct with training data is: \"+np.str(fraction_correct)+\"**\")\n",
        "\n",
        "if fraction_correct < 0.6:\n",
        "    printmd('**Warning: very poor performance on training data; likely error**')\n",
        "\n",
        "#print('Tidying up - removing h5 file and scale file if it exists')\n",
        "os.remove(h5file)\n",
        "if scale_exists:\n",
        "  os.remove(scalefile)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "68893cf9d03b20f47e12b8db53c70f876a3cecd9a1ccf7cfa1ef1af3733fe685"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
